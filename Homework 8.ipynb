{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have a network of three neurons with activity (firing rate) given by $x_1 $, $x_2 $, $x_3 $, respectively. The neurons are arranged in a sequence and the firing rate of neuron 3 is given by:\n",
    "#### $x_3 = w_2 x_2 = w_2 w_1 x_1 $\n",
    "#### where, $w_1 $ and $w_2 $ are the synaptic weights connecting neuron 1 to neuron 2 and neuron 2 to neuron 3, respectively.\n",
    "#### The goal is to train this network such that the firing rate of neuron 3 matches a target firing rate $y $. In order to do so, we use a quadratic loss function given by:\n",
    "#### $l(y, x_3) = \\frac{1}{2}(y-x_3)^2 $\n",
    "#### Our goal is to determine the set of weights for which the loss function is minimized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Warm-up. If $x_1 > 0 $, $w_1 < 0 $, and $x_3 < y $, should $w_2 $ increase or decrease to improve the loss? Should $w_1 $ increase or decrease?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The loss function is given by:\n",
    "#### $l(y, x_3) = \\frac{1}{2}(y-x_3)^2 $\n",
    "#### Hence improving loss is equivalent to decreasing: $ y-x_3 = w_2 w_1 x_1 - x_3 $\n",
    "#### If $x_1 > 0 $, $w_1 < 0 $, then $w_1 x_1 < 0 $\n",
    "#### Since $x_3 < y $, in order to improve loss, $x_3 $ needs to increase. Therefore, we want: $ w_2 w_1 x_1 > 0$.\n",
    "#### The only way that can happen is if: $ w_2 < 0 $\n",
    "#### Therefore, $w_2 $ should decrease to improve the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To be more precise than the above procedure, we use gradient descent, which computes derivatives of the loss function with respect to the synaptic weights, and then uses these derivatives to iteratively update the weights. Backpropagation is simply a procedure for computing these derivatives by the chain rule taught in any standard calculus course.\n",
    "## b) Compute the derivative of $l $ with respect to $x_3 $. Then, using the chain rule compute the derivatives with respect to $w_2 $, $x_2 $ and $w_1 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The loss function is given by:\n",
    "#### $l(y, x_3) = \\frac{1}{2}(y-x_3)^2 $\n",
    "#### Computing the derivative of $l $ with respect to $x_3 $:\n",
    "#### $\\frac{d}{dx_3} l(y, x_3)  = \\frac{d}{dx_3} \\frac{1}{2} (y-x_3)^2 $\n",
    "#### $\\therefore \\frac{d}{dx_3} l(y, x_3)  = \\frac{1}{2} \\times 2 (y-x_3) \\times \\frac{d}{dx_3} (y-x_3) $\n",
    "#### $\\therefore \\frac{d}{dx_3} l(y, x_3)  = (y-x_3) \\times (-1) $\n",
    "#### $\\therefore \\frac{d}{dx_3} l(y, x_3)  = (x_3-y) $\n",
    "#### $\\because x_3 = w_2 x_2 $, we can rewrite the partial derivate wrt $w_2 $ as:\n",
    "#### $\\frac{\\partial}{\\partial w_2} l(y, x_3) = \\frac{\\partial}{\\partial x_3} l(y, x_3) \\times \\frac{\\partial x_3}{\\partial w_2} $\n",
    "#### $\\therefore \\frac{\\partial}{\\partial w_2} l(y, x_3) = (x_3-y) \\times \\frac{\\partial w_2 x_2}{\\partial w_2} $\n",
    "#### $\\therefore \\frac{\\partial}{\\partial w_2} l(y, x_3) = (x_3-y) x_2$\n",
    "#### Similarly, the partial derivative wrt $x_2 $ can be written as: \n",
    "#### $\\frac{\\partial}{\\partial x_2} l(y, x_3) = \\frac{\\partial}{\\partial x_3} l(y, x_3) \\times \\frac{\\partial x_3}{\\partial x_2} $\n",
    "#### $\\therefore \\frac{\\partial}{\\partial x_2} l(y, x_3) = (x_3-y) \\times \\frac{\\partial w_2 x_2}{\\partial x_2} $\n",
    "#### $\\therefore \\frac{\\partial}{\\partial x_2} l(y, x_3) = (x_3-y) w_2$\n",
    "#### We also have: $x_3 = w_2 w_1 x_1 $, therefore we can rewrite the partial derivative wrt $w_1 $ as:\n",
    "#### $\\frac{\\partial}{\\partial w_1} l(y, x_3) = \\frac{\\partial}{\\partial x_3} l(y, x_3) \\times \\frac{\\partial x_3}{\\partial w_1} $\n",
    "#### $\\therefore \\frac{\\partial}{\\partial w_1} l(y, x_3) = (x_3-y) \\times \\frac{\\partial w_2 w_1 x_1}{\\partial w_1} $\n",
    "#### $\\therefore \\frac{\\partial}{\\partial w_1} l(y, x_3) = (x_3-y) w_2 x_1$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
