{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf5bcefc",
   "metadata": {},
   "source": [
    "Q1. Fraction of supragranular neurons is defined as the ratio of the number of neurons from A \\\n",
    "projecting to B to the total number of neurons projecting to B. This helps define hierarchical \\\n",
    "position as it provides a metric to define the ratio of inputs being received to a region from another region.\n",
    "\n",
    "Q2. \n",
    "The network is of size 6. The number of networks possible with k connections is given by: \\\n",
    "${N - 1\\choose k} $ \\\n",
    "Therefore, number of networks with k = 0 is 1, number of networks with k = 1 is 5, \\\n",
    "number of networks with k = 2 is 10, number of networks with k = 3 is 10, \\\n",
    "number of networks with k = 4 is 5, and the number of networks with k = 5 is 1. \\\n",
    "Therefore, the total number of possible networks is 1+5+10+10+5+1 = 32. \\\n",
    "Since all networks are equally likely, the probability of the given network is 1/32.\n",
    "\n",
    "\n",
    "(b) The network has a size of 6, with each node being connected to another with a probability \\\n",
    "of 0.5. And we have a particular network configuration: \\\n",
    "For a network of size 6, the probability of it have k connections is given by: \\\n",
    "$P(k) = {N - 1\\choose k} p^k (1-p)^{N-1-k}$ \\\n",
    "Therefore, for k = 4, we have: \\\n",
    "$P(4) = {6 - 1\\choose 4} \\times 0.5^4 \\times (1-0.5)^{6-1-4}$ \\\n",
    "Therefore,\n",
    "$P(4) = {5\\choose 4} \\times 0.0625 \\times 0.5$ \\\n",
    "Therefore,\n",
    "$P(4) = 5 \\times 0.0625 \\times 0.5$ \\\n",
    "Therefore,\n",
    "$P(4) = 0.15625$ \n",
    "\n",
    "Q3. For short-term depression (STD) of a synapse, the equation is given by: \\\n",
    "$dD/dt = -P_rel * D * \\sum_j \\delta(t-t_j) + (1-D)/\\tau_D $\\\n",
    "Here, after each burst, the average D is reduced on each burst by $(1-P_rel)D $ \\ \n",
    "and it recovers with a time-constant $\\tau_D $, thereby resulting in synaptic depression. \\\n",
    "For short-term facilitation (STF) of a synapse, the equation is given by: \\\n",
    "$dU/dt = U \\sum_j \\delta(t-t_j)(1-u) + (U-u)/\\tau_F $ \\\n",
    "Here, after each burst the average U increases, and there is a recovery time-period defined \\\n",
    "by the time-constant $\\tau_F $. Hemce, there will be synaptic facilitation, in this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71200c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+5+10+10+5+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9c51d0",
   "metadata": {},
   "source": [
    "Q1. For the dynamical equation, we have: \\\n",
    "$\\tau_E \\frac{dr_E}{dt} = -r_E + J_{EE} r_E + I_{E,ext} $ \\\n",
    "At steady-state, we have: \\\n",
    "$r_E = \\frac{I_{E,ext}}{1-J_{EE}} $ \\\n",
    "If $J_{EE} = 1 $, we have: \\\n",
    "$\\tau_E \\frac{dr_E}{dt} = I_{E,ext} $ \\\n",
    "which makes it a perfect neural integrator. \\\n",
    "\n",
    "Q2. In the Wilson-Cowan firing rate model, we have oscillations when we have delayed fast depressions.\n",
    "\n",
    "Q3. We have the dynamical system: \\\n",
    "$\\frac{dr/dt} = -r + S(wr + I) $ \\\n",
    "The dynamics has a fixed point, when $\\frac{dr}{dt} = 0 $ \\\n",
    "i.e. when, \\\n",
    "$S(wr+I) = r $ \\\n",
    "This is what is captured in the graphs on the right. Specifically, like y = r and y = S(wr+I) intersect at different locations based on the value of I. Increasing the value of I, will shift the sigmoid to the left. Therefore, we can go from the first plot to the second plot by increasing I and similarly from the second plot to the third plot by increasing I further.\n",
    "There are three fixed points in the second plot. The left-most and the right-most fixed points are stable fixed-points, whereas the middle fixed point is an unstable fixed point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e72a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "635bcf2f",
   "metadata": {},
   "source": [
    "1. The ring model produces contrast invariance by taking into account not just the external input but also non-specific cortical suppression and net excitation.\n",
    "2. The probability of making an error in the Hopfield model relates to the number of patterns M and the number of neurons N as approximately $ \\sqrt{M/N} $ for large M and N with the scenario $M << N $. This implies that the probability of making an error decreases as the network size increases  and the probability of making an error as the number of patterns memorized by the network increase.\n",
    "3. To make sense of the model in terms of spikes, we can let $S_i = 2x_i - 1 $, where $x_i $ is either 0 or 1. The Hopfield model in terms of $S_i $ is: \\\n",
    "$S_i(t+1) = sgn(\\sum_j w_{ij}S_j(t)) $\\\n",
    "Substituting, we get: \\\n",
    "$2x_i(t+1)-1 = sgn(\\sum_j w_{ij}(2x_j(t)-1)) $\\\n",
    "Therefore, \\\n",
    "$x_i(t+1) = (1+sgn(\\sum_j w_{ij}(2x_j(t)-1)))/2 $\\\n",
    "The input potential is : $h_i = \\sum_j w_{ij}x_j $ in the scenario where $\\sum_j w_{ij}x_j = 1 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de848b51",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d842370",
   "metadata": {},
   "source": [
    "1. Hopfield network has attractor dynamics and hence patterns that are similar to each other have a similar representation. Adding a slight noise to the input does not change the distance between two inputs $ x_1 $ and $x_1^{'}$.\n",
    "2. STDP is a modification of Hebb's rule by accounting for temporal relationship between spikes of pre and post synaptic cells. Hebb's rule does not provide a framework to model weakening of synapses. This is addressed by STDP.\n",
    "3. Short-term synaptic pasticity occurs over shorter timescales whereas Long-term synaptic plasticity occurs over longer timescales. Hence the correct answer choice is D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a55e164",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a37d1537",
   "metadata": {},
   "source": [
    "1. Short-term memory referes to maintenance of stimulus infomration after the stimulus is gone. Working memory is a form of short-term memory that can be manipulated. \n",
    "2. Wong-Wang model uses the working memory recurrent network model and introduces a winner-take-all read-out from the population based on threshold, thereby converting a WM model into a decision-making model.\n",
    "3. The coherence level of the stimulus alters the probability of the model going into one of the two attractor states, with the probability of the correct attractor state increasing as a function of coherence. This models the behavioral performance of the animal well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b03bfc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b73041a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
